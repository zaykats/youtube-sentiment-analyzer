# YouTube Sentiment Analyzer 

Syst√®me MLOps complet pour analyser le sentiment des commentaires YouTube en temps r√©el avec une pr√©cision de **89.12%**.

##  Fonctionnalit√©s

- **Mod√®le ML haute performance** : TF-IDF + Logistic Regression optimis√© avec GridSearchCV
- **API REST** : FastAPI d√©ploy√©e sur Hugging Face Spaces
- **Extension Chrome** : Analyse en temps r√©el des commentaires YouTube
- **Pipeline MLOps complet** : De la collecte de donn√©es au d√©ploiement

## Performance du Mod√®le

### M√©triques Globales
- **Accuracy** : **89.12%** 
- **F1-Score (weighted)** : **0.8902** 
- **Dataset** : 36,982 commentaires Reddit
- **Train/Test Split** : 29,585 / 7,397 (80/20)

### Performance par Classe

| Sentiment | Precision | Recall | F1-Score | Support |
|-----------|-----------|--------|----------|---------|
| N√©gatif (-1) | 0.85 | 0.79 | 0.82 | 1,656 |
| Neutre (0) | 0.89 | 0.96 | 0.92 | 2,575 |
| Positif (1) | 0.91 | 0.89 | 0.90 | 3,166 |

### Optimisation
- **Algorithme** : GridSearchCV (5-fold cross-validation)
- **Meilleurs hyperparam√®tres** :
  - `C`: 10.0
  - `solver`: liblinear
  - `max_iter`: 200
- **Score CV** : 0.8794

### Temps d'Inf√©rence
- **Batch de 50 commentaires** : < 1ms 
- **Temps moyen par commentaire** : < 0.02ms

##  Structure du Projet

```
youtube-sentiment-analyzer/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Donn√©es brutes (reddit.csv)
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es nettoy√©es (train.csv, test.csv)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_model.joblib # Mod√®le entra√Æn√©
‚îÇ   ‚îî‚îÄ‚îÄ vectorizer.joblib      # Vectoriseur TF-IDF
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ download_data.py   # T√©l√©chargement du dataset
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clean_data.py      # Nettoyage et preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py     # Entra√Ænement et optimisation
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îî‚îÄ‚îÄ app.py             # API FastAPI
‚îú‚îÄ‚îÄ chrome-extension/           # Extension Chrome
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png   # Visualisation des performances
‚îú‚îÄ‚îÄ tests/                      # Tests unitaires
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile                  # Configuration Docker
‚îî‚îÄ‚îÄ README.md                   # Documentation
```

##  Installation

### Pr√©requis
- Python 3.10+
- Git
- Compte Hugging Face (pour le d√©ploiement)
- Google Chrome (pour l'extension)

### √âtapes d'installation

```bash
# 1. Cloner le repository
git clone https://github.com/zaykats/youtube-sentiment-analyzer
cd youtube-sentiment-analyzer

# 2. Cr√©er l'environnement virtuel
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# 3. Installer les d√©pendances
pip install --upgrade pip
pip install -r requirements.txt
```

##  Utilisation

### 1Ô∏è T√©l√©charger et Pr√©parer les Donn√©es

```bash
# T√©l√©charger le dataset Reddit Sentiment
python src/data/download_data.py

# Nettoyer et pr√©parer les donn√©es
python src/data/clean_data.py
```

**Output attendu** :
- `data/raw/reddit.csv` : Dataset brut (36,982 commentaires)
- `data/processed/train.csv` : Donn√©es d'entra√Ænement (29,585)
- `data/processed/test.csv` : Donn√©es de test (7,397)

### 2Ô∏è Entra√Æner le Mod√®le

```bash
python src/models/train_model.py
```

**Output attendu** :
```
 Accuracy : 0.8912 (89.12%)
 F1-Score : 0.8902
 Mod√®le sauvegard√© : models/sentiment_model.joblib
 Matrice de confusion : logs/confusion_matrix.png
```

### 3Ô∏è Lancer l'API Localement

```bash
# D√©marrer l'API FastAPI
python src/api/app.py

# L'API sera disponible sur http://localhost:8000
```

**Endpoints disponibles** :
- `GET /` : Informations sur l'API
- `GET /health` : V√©rification de l'√©tat
- `POST /predict_batch` : Analyse de sentiment par batch

### 4Ô∏è Tester l'API

```bash
# Test de sant√©
curl http://localhost:8000/health

# Test de pr√©diction
curl -X POST "http://localhost:8000/predict_batch" \
     -H "Content-Type: application/json" \
     -d '{
       "comments": [
         "This is amazing! I love it!",
         "This is terrible, waste of time",
         "It's okay, nothing special"
       ]
     }'
```

**R√©ponse attendue** :
```json
{
  "predictions": [
    {
      "comment": "This is amazing! I love it!",
      "sentiment": "positive",
      "sentiment_label": 1,
      "confidence": 0.95
    },
    ...
  ],
  "statistics": {
    "total_comments": 3,
    "positive_count": 1,
    "neutral_count": 1,
    "negative_count": 1,
    "positive_percentage": 33.33,
    "neutral_percentage": 33.33,
    "negative_percentage": 33.33,
    "average_confidence": 0.89
  },
  "processing_time": 0.023
}
```

##  D√©ploiement Docker

### Build l'image Docker

```bash
docker build -t youtube-sentiment-api .
```

### Lancer le container

```bash
docker run -p 7860:7860 youtube-sentiment-api
```

### D√©ployer sur Hugging Face Spaces

1. Cr√©ez un Space sur [huggingface.co/spaces](https://huggingface.co/spaces)
2. S√©lectionnez **Docker** comme SDK
3. Clonez votre Space localement
4. Copiez les fichiers n√©cessaires :
   - `src/api/app.py` ‚Üí `app_api.py`
   - `models/` ‚Üí `models/`
   - `Dockerfile`
   - `requirements.txt`
5. Poussez vers Hugging Face

```bash
git push
```

##  Tests et Validation

### Tests Unitaires

```bash
# Ex√©cuter tous les tests
pytest tests/

# Tests avec couverture
pytest --cov=src tests/
```

### Tests de Performance

```bash
# Test de charge API
python tests/load_test.py
```

##  Analyse des R√©sultats

### Matrice de Confusion

La matrice de confusion montre la r√©partition des pr√©dictions :

```
Vrai\Pr√©dit  N√©gatif  Neutre  Positif
N√©gatif       1307     130     219
Neutre          56    2461      58
Positif        171     171    2824
```

**Interpr√©tation** :
-  Le mod√®le excelle dans la d√©tection des commentaires **neutres** (96% recall)
-  Bonne performance sur les commentaires **positifs** (89% recall)
-  L√©g√®re confusion entre n√©gatifs et positifs (10-15% d'erreur crois√©e)

### Points Forts
1. **√âquilibre** : Bonne performance sur les 3 classes
2. **Rapidit√©** : Inf√©rence ultra-rapide (< 1ms pour 50 commentaires)
3. **Robustesse** : F1-Score > 0.82 pour toutes les classes

### Am√©liorations Futures
- [ ] Utiliser des embeddings pr√©-entra√Æn√©s (Word2Vec, BERT)
- [ ] Augmenter le dataset avec des commentaires YouTube r√©els
- [ ] Impl√©menter un syst√®me de re-entra√Ænement continu
- [ ] Ajouter la d√©tection de sarcasme et d'ironie

##  Technologies Utilis√©es

### Machine Learning
- **scikit-learn** : Mod√®le et vectorisation
- **pandas** : Manipulation de donn√©es
- **numpy** : Calculs num√©riques

### API & Backend
- **FastAPI** : Framework web moderne
- **uvicorn** : Serveur ASGI
- **pydantic** : Validation de donn√©es

### DevOps & D√©ploiement
- **Docker** : Containerisation
- **Hugging Face Spaces** : H√©bergement cloud
- **Git** : Version control

### Frontend
- **Chrome Extension API** : Int√©gration navigateur
- **JavaScript** : Logique frontend
- **HTML/CSS** : Interface utilisateur

### Architecture du Mod√®le

```
Input Text ‚Üí TF-IDF Vectorizer ‚Üí Logistic Regression ‚Üí Sentiment Prediction
              (5000 features)      (optimized params)     (-1, 0, 1)
```

**Vectoriseur TF-IDF** :
- `max_features`: 5000
- `ngram_range`: (1, 2) - unigrammes et bigrammes
- `min_df`: 2 - terme doit appara√Ætre dans au moins 2 documents
- `max_df`: 0.9 - ignore termes trop fr√©quents

**Logistic Regression** :
- `C`: 10.0 - r√©gularisation inverse
- `solver`: liblinear - optimis√© pour petits datasets
- `max_iter`: 200 - nombre d'it√©rations

##  Projet Acad√©mique

**Institution** : √âcole Nationale Sup√©rieure d'Arts et M√©tiers (ENSAM) - Rabat  
**Fili√®re** : INDIA  
**Module** : Virtualisation & Cloud Computing  
**Ann√©e Universitaire** : 2025/26

## üë®‚Äçüíª Auteur

Zaykats

##  Remerciements

- Dataset Reddit Sentiment : [Himanshu-1703](https://github.com/Himanshu-1703/reddit-sentiment-analysis)
- FastAPI Documentation
- scikit-learn Community
- Hugging Face Spaces

---

‚≠ê **Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile !**

 **Questions ou suggestions ?** Ouvrez une issue sur GitHub !